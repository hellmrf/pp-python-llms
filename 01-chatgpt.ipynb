{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizando Modelos de Linguagem de Grande Escala (LLM) em Python\n",
    "\n",
    "‚úèÔ∏è Por [Heliton Martins](https://hellmrf.dev.br) | 01 de agosto de 2024 | [üå± Programa√ß√£o Popular](https://youtube.com/@programacaopopular).\n",
    "\n",
    "## OpenAI GPT 4o\n",
    "\n",
    "Usaremos neste notebook os seguintes modelos (LLMs):\n",
    "- **OpenAI GPT** (pago)\n",
    "    - üóùÔ∏è [Chaves de API](https://platform.openai.com/api-keys) (pegue sua chave aqui)\n",
    "    - üìÑ [Documenta√ß√£o](https://platform.openai.com/docs/overview)\n",
    "\n",
    "**Para acessar a API da OpenAI √© necess√°rio ter uma conta de desenvolvedor com cr√©ditos** em https://platform.openai.com. Isso n√£o tem nada a ver com o ChatGPT Pro. Mesmo que voc√™ seja assinante do ChatGPT Pro, ser√° necess√°rio carregar sua conta com cr√©ditos para come√ßar a usar a API.\n",
    "\n",
    "A recarga m√≠nima √© de US\\$ 5 (R\\$ 28,76 em 01 de agosto de 2024). Ap√≥s carregada, os cr√©ditos s√£o cobrados por n√∫mero de tokens enviados e recebidos com a sua chave de API, mas uma consulta relativamente pequena costuma custar menos de US$ 0,01 (um centavo de d√≥lar). Eu uso a API para testes h√° alguns meses e nunca usei todos os meus US\\$ 5 em cr√©ditos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depend√™ncias\n",
    "\n",
    "Execute a c√©lula a seguir para instalar as depend√™ncias no Google Colab. Caso voc√™ esteja em um ambiente local, pode usar o comando `pip install <pacote>` pelo terminal.\n",
    "\n",
    "- [üìÑ Documenta√ß√£o do LangChain](https://python.langchain.com/v0.2/docs/integrations/chat/openai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-openai # Se voc√™ for usar a OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credenciais\n",
    "\n",
    "Para configurar suas chaves de API\n",
    "1. Copie o arquivo `.env.sample` para `.env`, e inclua nele suas chaves de API. Esse arquivo **n√£o deve ser commitado**, j√° que cont√©m informa√ß√µes sens√≠veis que permitem a qualquer um usar suas cotas nas APIs.\n",
    "2. Execute a c√©lula a seguir e continue. Caso a chave de API n√£o seja encontrada no arquivo `.env`, elas ser√£o solicitadas.\n",
    "\n",
    "Caso esteja em ambiente local e n√£o queira usar o arquivo `.env` ou o mecanismo de oculta√ß√£o das chaves, basta defin√≠-las explicitamente:\n",
    "\n",
    "```python\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR-API-KEY\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain com GPT\n",
    "\n",
    "A partir de agora, em vez de usar o binding oficial para Python, utilizaremos a vers√£o disponibilizada pela comunidade do Langchain. O Langchain √© uma biblioteca que facilita a constru√ß√£o de aplica√ß√µes que utilizam modelos de linguagem, como o GPT ou o Gemini, de forma mais eficiente e integrada. Ela oferece ferramentas e abstra√ß√µes para gerenciar fluxos de conversa√ß√£o, integra√ß√£o com APIs de modelos de linguagem, e manipula√ß√£o de dados de entrada e sa√≠da, permitindo que desenvolvedores criem aplica√ß√µes complexas com menos esfor√ßo e maior flexibilidade.\n",
    "\n",
    "Em s√≠ntese, √© poss√≠vel desenvolver toda a l√≥gica da aplica√ß√£o e apenas \"plugar\" o modelo de linguagem desejado, o que inclusive facilita testar e comparar os modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√£o, os c√£es n√£o voam. Eles s√£o animais terrestres e n√£o possuem a capacidade de voar como aves ou insetos. No entanto, existem algumas situa√ß√µes em que c√£es podem ser transportados em avi√µes, mas isso n√£o significa que eles possam voar por conta pr√≥pria. Se voc√™ est√° se referindo a algo mais metaf√≥rico ou a uma situa√ß√£o espec√≠fica, sinta-se √† vontade para esclarecer!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"Os c√£es voam?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso, conectamos ao ChatGPT e geramos uma resposta utilizando Python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coraldigital",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
