{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizando Modelos de Linguagem de Grande Escala (LLM) em Python\n",
    "\n",
    "‚úèÔ∏è Por [Heliton Martins](https://hellmrf.dev.br) | 01 de agosto de 2024 | [üå± Programa√ß√£o Popular](https://youtube.com/@programacaopopular).\n",
    "\n",
    "## Usando LLMs com Langchain\n",
    "\n",
    "Usaremos neste notebook os seguintes modelos (LLMs):\n",
    "\n",
    "- **OpenAI GPT 4o** (pago)\n",
    "    - üóùÔ∏è [Chaves de API](https://platform.openai.com/api-keys) (pegue sua chave aqui)\n",
    "    - üìÑ [Documenta√ß√£o](https://platform.openai.com/docs/overview)\n",
    "    - üí∞ Necess√°rio recarregar a conta em no m√≠nimo US$ 5,00 (R$ 28,76 na data da escrita deste documento);\n",
    "      - Observe que o modelo `gpt-4o-mini` √© consideravelmente mais barato do que a vers√£o completa `gpt-4o`.\n",
    "      - [Pre√ßos](https://openai.com/api/pricing/)\n",
    "- **Google Gemini 1.5** (gratuito com limites)\n",
    "    - üóùÔ∏è [Google AI Studio](https://aistudio.google.com/app/prompts/new_chat) (pegue sua chave aqui)\n",
    "    - üìÑ [Documenta√ß√£o](https://ai.google.dev/gemini-api/docs)\n",
    "    - üí∞ Gratuito, mas com limites no n√∫mero de **R**equisi√ß√µes **P**or **M**inuto (RPM)\n",
    "      - 2 RPM para o Gemini 1.5 Pro;\n",
    "      - 15 RPM para o Gemini 1.5 Flash.\n",
    "\n",
    "### OpenAI API\n",
    "\n",
    "**Para acessar a API da OpenAI √© necess√°rio ter uma conta de desenvolvedor com cr√©ditos** em https://platform.openai.com. Isso n√£o tem nada a ver com o ChatGPT Pro. Mesmo que voc√™ seja assinante do ChatGPT Pro, ser√° necess√°rio carregar sua conta com cr√©ditos para come√ßar a usar a API.\n",
    "\n",
    "Acesse a [Central de Pagamentos](https://platform.openai.com/settings/organization/billing/overview) e adicione um m√©todo de pagamento. A recarga m√≠nima √© de US$ 5 (R$ 28,76 em 01 de agosto de 2024). Ap√≥s carregada, a cobran√ßa √© feita por n√∫mero de tokens enviados/recebidos com a sua chave de API, mas uma consulta relativamente pequena costuma custar menos de US$ 0,01 (um centavo de d√≥lar). Eu uso a API para testes h√° alguns meses e usei apenas US\\$ 4 at√© hoje (mas √© claro que, sempre que poss√≠vel, eu procuro usar modelos gratuitos).\n",
    "\n",
    "Com a conta ativada, acesse a tela de [Chaves de API](https://platform.openai.com/api-keys) e gere a sua.\n",
    "\n",
    "### N√£o tenho uma chave de API\n",
    "\n",
    "Infelizmente, se voc√™ n√£o tem uma chave de API, n√£o √© poss√≠vel utilizar a API do ChatGPT. Use outro modelo gratuito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depend√™ncias\n",
    "\n",
    "Execute a c√©lula a seguir para instalar as depend√™ncias no Google Colab. Caso voc√™ esteja em um ambiente local, pode usar o comando `pip install <pacote>` pelo terminal.\n",
    "\n",
    "- [üìÑ Documenta√ß√£o da integra√ß√£o com a OpenAI do LangChain](https://python.langchain.com/v0.2/docs/integrations/chat/openai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-openai # Se voc√™ for usar OpenAI\n",
    "%pip install -qU langchain-google-genai # Se voc√™ for usar Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credenciais\n",
    "\n",
    "Para configurar suas chaves de API\n",
    "1. Copie o arquivo `.env.sample` para `.env`, e inclua nele suas chaves de API. Esse arquivo **n√£o deve ser commitado**, j√° que cont√©m informa√ß√µes sens√≠veis que permitem a qualquer um usar suas cotas nas APIs.\n",
    "2. Execute a c√©lula a seguir e continue. Caso a chave de API n√£o seja encontrada no arquivo `.env`, elas ser√£o solicitadas.\n",
    "\n",
    "Caso esteja em ambiente local e n√£o queira usar o arquivo `.env` ou o mecanismo de oculta√ß√£o das chaves, basta defin√≠-las explicitamente:\n",
    "\n",
    "```python\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR-API-KEY\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executando modelos OpenAI (GPT)\n",
    "\n",
    "A partir de agora, em vez de usar o binding oficial para Python, utilizaremos a vers√£o disponibilizada pela comunidade do Langchain. O Langchain √© uma biblioteca que facilita a constru√ß√£o de aplica√ß√µes que utilizam modelos de linguagem, como o GPT ou o Gemini, de forma mais eficiente e integrada. Ela oferece ferramentas e abstra√ß√µes para gerenciar fluxos de conversa√ß√£o, integra√ß√£o com APIs de modelos de linguagem, e manipula√ß√£o de dados de entrada e sa√≠da, permitindo que desenvolvedores criem aplica√ß√µes complexas com menos esfor√ßo e maior flexibilidade.\n",
    "\n",
    "Em s√≠ntese, √© poss√≠vel desenvolver toda a l√≥gica da aplica√ß√£o e apenas \"plugar\" o modelo de linguagem desejado, o que inclusive facilita testar e comparar os modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m[Humano]:\u001b[0m Os c√£es voam?\n",
      "\u001b[1m\u001b[92m[GPT-4o Mini]:\u001b[0m N√£o, os c√£es n√£o voam. Eles s√£o animais terrestres e n√£o possuem a capacidade de voar como aves ou insetos. No entanto, em algumas situa√ß√µes, como em avi√µes, os c√£es podem ser transportados pelo ar, mas isso n√£o significa que eles possam voar por conta pr√≥pria. Se voc√™ est√° se referindo a algo mais metaf√≥rico ou a uma situa√ß√£o espec√≠fica, sinta-se √† vontade para esclarecer!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "prompt = \"Os c√£es voam?\"\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(f\"{color.BOLD + color.BLUE}[Humano]:{color.END} {prompt}\")\n",
    "print(f\"{color.BOLD + color.GREEN}[GPT-4o Mini]:{color.END} {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso, conectamos ao ChatGPT e geramos uma resposta utilizando Python.\n",
    "\n",
    "### Executando modelos Google (Gemini)\n",
    "\n",
    "Embora j√° tenhamos executado o Gemini 1.5 no notebook anterior, l√° fizemos usando o binding oficial do google (`from google.genai import ...`). Aqui segue o c√≥digo em LangChain. A vantagem de Langchain, como observamos, √© que a interface √© a mesma para todos os modelos, facilitando a troca de modelos para testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m[Humano]:\u001b[0m Os c√£es voam?\n",
      "\u001b[1m\u001b[92m[Gemini 1.5 Flash]:\u001b[0m N√£o, os c√£es n√£o voam. Os c√£es s√£o mam√≠feros terrestres e n√£o t√™m asas. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI   # Alterei aqui\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(                               # ... e aqui\n",
    "    model=\"models/gemini-1.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "prompt = \"Os c√£es voam?\"\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(f\"{color.BOLD + color.BLUE}[Humano]:{color.END} {prompt}\")\n",
    "print(f\"{color.BOLD + color.GREEN}[Gemini 1.5 Flash]:{color.END} {response.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coraldigital",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
